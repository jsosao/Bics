name: Converter Solo Eventos Alfa M3U

on:
  schedule:
    - cron: '0 14 * * *'  # Se ejecuta diariamente a las 08 am
  workflow_dispatch:  # Permite ejecuci√≥n manual

jobs:
  convert:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'

    - name: Download and convert M3U file
      env:
        M3U_URL: ${{ secrets.ALFA_M3U_URL }}
      run: |
        cd $GITHUB_WORKSPACE
        python3 << 'EOF'
        import urllib.request
        import re
        import os
        import json
        import unicodedata

        # URL del archivo M3U desde variable de entorno (GitHub Secret)
        url = os.environ.get('M3U_URL')
        if not url:
            print("‚ùå ERROR: No se encontr√≥ la variable M3U_URL")
            print("Verifica que el secret ALFA_M3U_URL est√© configurado en GitHub")
            exit(1)
        
        print(f"‚úì URL cargada desde secret ALFA_M3U_URL correctamente")
        
        # Descargar el archivo
        print("\nDescargando archivo M3U...")
        try:
            with urllib.request.urlopen(url) as response:
                content = response.read().decode('utf-8')
            print("‚úì Archivo M3U descargado exitosamente")
        except Exception as e:
            print(f"‚ùå Error al descargar el archivo M3U: {e}")
            exit(1)
        
        # Logo por defecto
        default_logo = "https://raw.githubusercontent.com/jsosao/Bics/main/picons/no_logo.png"
        picons_base_url = "https://raw.githubusercontent.com/jsosao/Bics/main/picons/"

        # ============================================================
        # FUNCIONES AUXILIARES
        # ============================================================
        
        def normalize_text(text):
            """Normaliza el texto removiendo acentos, espacios y caracteres especiales"""
            # Remover acentos
            text = unicodedata.normalize('NFD', text)
            text = ''.join(char for char in text if unicodedata.category(char) != 'Mn')
            
            # Eliminar prefijos comunes
            prefixes_to_remove = ["CINE - ", "DEPORTES - ", "CINE -", "DEPORTES -","DOC-", "NOV-", "MUS-", "INF-"]
            for prefix in prefixes_to_remove:
                # Eliminar como palabra completa
                text = re.sub(r'\b' + prefix + r'\b', '', text, flags=re.IGNORECASE)
            
            # Convertir a min√∫sculas y reemplazar espacios y caracteres especiales
            text = re.sub(r'[^\w\s]', '', text.lower())
            text = re.sub(r'\s+', '_', text.strip())
            
            return text
        
        def get_github_directory_contents(api_url):
            """Obtiene el contenido de un directorio de GitHub usando la API"""
            try:
                req = urllib.request.Request(api_url)
                req.add_header('User-Agent', 'Mozilla/5.0')
                
                with urllib.request.urlopen(req) as response:
                    if response.status == 200:
                        data = response.read().decode('utf-8')
                        return json.loads(data)
                    else:
                        print(f"‚ö† Error al acceder a {api_url}: {response.status}")
                        return []
            except Exception as e:
                print(f"‚ö† Error al obtener contenido: {e}")
                return []
        
        def scan_directory_recursive(path=""):
            """Escanea recursivamente todos los directorios para encontrar archivos PNG"""
            api_url = f"https://api.github.com/repos/jsosao/Bics/contents/picons{path}"
            contents = get_github_directory_contents(api_url)
            
            logos = []
            
            for item in contents:
                if item['type'] == 'file' and item['name'].endswith('.png'):
                    # Crear la URL completa del logo
                    logo_url = picons_base_url + path.lstrip('/') + ('/' if path else '') + item['name']
                    # Crear el nombre normalizado para b√∫squeda
                    logo_name = item['name'].replace('.png', '')
                    logos.append({
                        'name': logo_name,
                        'normalized_name': normalize_text(logo_name),
                        'url': logo_url,
                        'path': path
                    })
                elif item['type'] == 'dir':
                    # Omitir la carpeta "country"
                    if item['name'] not in ['country']:
                        subfolder_path = path + '/' + item['name']
                        logos.extend(scan_directory_recursive(subfolder_path))
            
            return logos
        
        def get_picons_list():
            """Obtiene la lista completa de picons disponibles en el repositorio"""
            try:
                print("Escaneando repositorio de logos recursivamente...")
                logos = scan_directory_recursive()
                print(f"‚úì Se encontraron {len(logos)} picons disponibles")
                return logos
            except Exception as e:
                print(f"‚ö† No se pudo obtener la lista de picons: {e}")
                return []
        
        def find_best_logo_match(title, picons_list):
            """Encuentra la mejor coincidencia de logo para un t√≠tulo dado"""
            if not picons_list:
                return None
            
            normalized_title = normalize_text(title)
            
            # B√∫squeda exacta
            for logo in picons_list:
                if logo['normalized_name'] == normalized_title:
                    print(f"  ‚Üí Coincidencia exacta: {logo['name']}")
                    return logo['url']
            
            # B√∫squeda por coincidencia parcial con puntuaci√≥n
            best_match = None
            max_score = 0
            
            for logo in picons_list:
                # Calcular similitud por palabras
                logo_words = set(logo['normalized_name'].split('_'))
                title_words = set(normalized_title.split('_'))
                
                # Intersecci√≥n de palabras
                common_words = logo_words.intersection(title_words)
                if len(common_words) > 0:
                    # Puntuaci√≥n basada en palabras comunes y longitud
                    score = len(common_words) / max(len(logo_words), len(title_words))
                    if score > max_score and score > 0.3:  # Umbral m√≠nimo de similitud
                        max_score = score
                        best_match = logo
            
            # Si encontramos una buena coincidencia por palabras, retornarla
            if best_match and max_score > 0.5:
                print(f"  ‚Üí Coincidencia por palabras ({int(max_score*100)}%): {best_match['name']}")
                return best_match['url']
            
            # B√∫squeda por contenido (substring)
            if not best_match:
                for logo in picons_list:
                    if len(logo['normalized_name']) >= 3:
                        if normalized_title in logo['normalized_name'] or logo['normalized_name'] in normalized_title:
                            # Verificar que la longitud sea razonable
                            if len(logo['normalized_name']) >= len(normalized_title) * 0.6:
                                print(f"  ‚Üí Coincidencia por substring: {logo['name']}")
                                return logo['url']
            
            # Si encontramos alguna coincidencia d√©bil, retornarla
            if best_match:
                print(f"  ‚Üí Coincidencia parcial ({int(max_score*100)}%): {best_match['name']}")
                return best_match['url']
            
            return None
        
        def clean_title(title):

            # Eliminar prefijos comunes
            prefixes_to_remove = ["CINE - ", "DEPORTES - ", "CINE -", "DEPORTES -","DOC-", "NOV-", "MUS-", "INF-"]
            for prefix in prefixes_to_remove:
                # Eliminar como palabra completa
                title = re.sub(r'\b' + prefix + r'\b', '', title, flags=re.IGNORECASE)
            
            """Limpia el t√≠tulo de prefijos no deseados"""
            # Eliminar todo lo que est√© dentro de par√©ntesis
            title = re.sub(r'\([^)]*\)', '', title)
            
            # Limpiar espacios m√∫ltiples
            title = re.sub(r'\s+', ' ', title).strip()
            
            return title
        
        def get_country(title):
            """Determina el pa√≠s basado en el t√≠tulo"""
            title_upper = title.upper()
            if title.startswith("AU") or "AUSTRALIA" in title_upper:
                return "au"
            elif title.startswith("UK") or "BBC" in title_upper or "BRITAIN" in title_upper:
                return "uk"
            elif title.startswith("US") or "USA" in title_upper:
                return "us"
            elif title.startswith("CA") or "CANADA" in title_upper:
                return "ca"
            elif title.startswith("ES") or "SPAIN" in title_upper or "ESPA√ëA" in title_upper:
                return "es"
            elif title.startswith("MX") or "MEXICO" in title_upper or "M√âXICO" in title_upper:
                return "mx"
            elif title.startswith("AR") or "ARGENTINA" in title_upper:
                return "ar"
            elif title.startswith("BR") or "BRASIL" in title_upper or "BRAZIL" in title_upper:
                return "br"
            elif title.startswith("FR") or "FRANCE" in title_upper or "FRANCIA" in title_upper:
                return "fr"
            else:
                return "us"  # Default
        
        def get_tag(group_title):
            """Determina el tag basado en el group-title"""
            group_lower = group_title.lower()
            if "sport" in group_lower or "deporte" in group_lower:
                return "Sports"
            elif "radio" in group_lower:
                return "Radio"
            elif "news" in group_lower or "noticias" in group_lower:
                return "News"
            elif "movie" in group_lower or "film" in group_lower or "peliculas" in group_lower or "cine" in group_lower:
                return "Movies"
            elif "series" in group_lower or "tv show" in group_lower:
                return "Series"
            elif "music" in group_lower or "musica" in group_lower:
                return "Music"
            elif "doc" in group_lower:
                return "Documentary"
            elif "kids" in group_lower or "infantil" in group_lower:
                return "Kids"
            else:
                return "General"
        
        def should_include_channel(group_title, channel_title):
            """Verifica si el canal debe ser incluido basado en grupo y t√≠tulo"""
            group_lower = group_title.lower()
            title_lower = channel_title.lower()
            
            # Incluir si el grupo contiene "(eventos)"
            if "(eventos)" in group_lower:
                return True
            
            # Incluir si el t√≠tulo contiene "CIELO SPORT"
            if "cielo sport" in title_lower:
                return True
            
            # Si no cumple ninguna condici√≥n, no incluir
            return False
        
        def escape_url(url):
            """Escapa la URL para el formato de salida"""
            url = url.replace("http://", "http[:[/][/]]")
            url = url.replace("https://", "https[:[/][/]]")
            url = url.replace(".", "[.]")
            url = url.replace("/", "[/]")
            return url

        # ============================================================
        # PROCESAMIENTO PRINCIPAL
        # ============================================================

        print("\n" + "="*60)
        print("OBTENIENDO LISTA DE PICONS DISPONIBLES")
        print("="*60)
        picons_list = get_picons_list()
        
        print("\n" + "="*60)
        print("PROCESANDO CANALES - PROYECTO")
        print("="*60)
        
        lines = content.strip().split('\n')
        entries = []
        skipped_count = 0
        logos_original = 0
        logos_found = 0
        logos_default = 0
        
        i = 0
        while i < len(lines):
            line = lines[i].strip()
            
            if line.startswith('#EXTINF:'):
                # Extraer informaci√≥n de la l√≠nea EXTINF
                tvg_name_match = re.search(r'tvg-name="([^"]*)"', line)
                tvg_logo_match = re.search(r'tvg-logo="([^"]*)"', line)
                group_title_match = re.search(r'group-title="([^"]*)"', line)
                
                # El t√≠tulo est√° al final de la l√≠nea despu√©s de la √∫ltima coma
                title_match = re.search(r',(.*)$', line)
                
                tvg_name = tvg_name_match.group(1) if tvg_name_match else ""
                tvg_logo = tvg_logo_match.group(1) if tvg_logo_match else ""
                group_title = group_title_match.group(1) if group_title_match else ""
                title = title_match.group(1).strip() if title_match else tvg_name

                # Guardar t√≠tulo original para verificaci√≥n
                original_title = title
                
                # Limpiar el t√≠tulo de prefijos no deseados
                title = clean_title(title)
                
                # La siguiente l√≠nea debe ser la URL del stream
                i += 1
                if i < len(lines):
                    stream_url = lines[i].strip()
                    
                    # Verificar si el canal debe ser incluido
                    if not should_include_channel(group_title, original_title):
                        print(f"‚äó Omitiendo: '{title}' | Grupo: '{group_title}'")
                        skipped_count += 1
                        i += 1
                        continue
                    
                    # Determinar el logo a usar
                    if tvg_logo and tvg_logo.strip():
                        final_logo = tvg_logo
                        logos_original += 1
                        print(f"‚úì '{title}' | Logo: Original | Grupo: '{group_title}'")
                    else:
                        # Buscar picon correspondiente
                        print(f"üîç Buscando logo para: '{title}' | Grupo: '{group_title}'")
                        matched_picon = find_best_logo_match(title, picons_list)
                        if matched_picon:
                            final_logo = matched_picon
                            logos_found += 1
                        else:
                            final_logo = default_logo
                            logos_default += 1
                            print(f"  ‚Üí Sin coincidencia, usando no_logo.png")
                    
                    # Crear la entrada
                    entry = {
                        'Artist': 'Alfa',
                        'Title': title,
                        'streamFormat': 'hls|mts',
                        'SwitchingStrategy': 'full-adaptation',
                        'Logo': final_logo,
                        'Stream': escape_url(stream_url),
                        'Live': True,
                        'Country': get_country(title),
                        'Tag': get_tag(group_title)
                    }
                    entries.append(entry)
            
            i += 1
        
        # Generar el archivo de salida
        output_lines = []
        for entry in entries:
            output_lines.append('{')
            output_lines.append(f'    Artist: "{entry["Artist"]}"')
            output_lines.append(f'    Title: "{entry["Title"]}"')
            output_lines.append(f'    streamFormat: "{entry["streamFormat"]}"')
            output_lines.append(f'    SwitchingStrategy: "{entry["SwitchingStrategy"]}"')
            output_lines.append(f'    Logo: "{entry["Logo"]}"')
            output_lines.append(f'    Stream: "{entry["Stream"]}"')
            output_lines.append(f'    Live: {str(entry["Live"]).lower()}')
            output_lines.append(f'    Country: "{entry["Country"]}"')
            output_lines.append(f'    Tag: "{entry["Tag"]}"')
            output_lines.append('}')
        
        output_content = '\n'.join(output_lines)
        
        # Guardar el archivo sin extensi√≥n
        output_path = "country/sports/eventos"
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(output_content)
        
        # Estad√≠sticas finales
        print("\n" + "="*60)
        print("RESUMEN FINAL - ALFA")
        print("="*60)
        print(f"‚úì Archivo guardado en: {output_path}")
        print(f"‚úì Total de canales procesados: {len(entries)}")
        print(f"‚äó Total de canales omitidos: {skipped_count}")
        print(f"\nDistribuci√≥n de logos:")
        print(f"  ‚úì Logos originales del M3U: {logos_original} ({logos_original*100//len(entries) if entries else 0}%)")
        print(f"  üîç Picons encontrados autom√°ticamente: {logos_found} ({logos_found*100//len(entries) if entries else 0}%)")
        print(f"  ‚ö† Logos default (no_logo.png): {logos_default} ({logos_default*100//len(entries) if entries else 0}%)")
        print(f"\nTotal con logo espec√≠fico: {logos_original + logos_found} ({(logos_original + logos_found)*100//len(entries) if entries else 0}%)")
        print("="*60)
        EOF
        
    - name: Commit and push changes
      run: |
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        git add country/sports/eventos
        git diff --staged --quiet || git commit -m "ü§ñü§ñ [Bot] Update eventos - $(date +'%Y-%m-%d %H:%M:%S')"        
        git push
