name: Validar Streams [x] Country

on:
  # Ejecutar manualmente
  workflow_dispatch:
    inputs:
      validate_urls:
        description: '¬øValidar URLs de streaming?'
        required: true
        default: 'true'
        type: choice
        options:
        - 'true'
        - 'false'
      update_file:
        description: '¬øActualizar archivo original?'
        required: true
        default: 'true'
        type: choice
        options:
        - 'true'
        - 'false'
  
  # Ejecutar autom√°ticamente cada d√≠a a las 8:00 AM UTC
  schedule:
    - cron: '0 8 * * *'
  
  # Ejecutar cuando se modifica alg√∫n archivo en el directorio Country
  push:
    paths:
      - 'country/country/**'

jobs:
  validate-streams:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Validar Streams
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        python << 'EOF'
        import urllib.request
        import urllib.error
        from urllib.parse import urlparse, urljoin
        import socket
        import re
        import json
        import base64
        import os
        import time
        
        def validate_stream_url(url, timeout=20):
            """
            Valida una URL de streaming verificando:
            1. Que la URL responda correctamente
            2. Que contenga contenido de streaming v√°lido (m3u8, mpd, o stream data)
            Incluye m√∫ltiples estrategias para evitar errores 403, 103 y connection reset
            """
            # Lista de User-Agents para rotar y evitar bloqueos
            user_agents = [
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0',
                'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:109.0) Gecko/20100101 Firefox/121.0',
                'VLC/3.0.18 LibVLC/3.0.18',
                'FFmpeg/4.4.2',
                'ExoPlayerLib/2.18.1'
            ]
            
            parsed_url = urlparse(url)
            if not parsed_url.scheme or not parsed_url.netloc:
                return False, "URL malformada"
            
            socket.setdefaulttimeout(timeout)
            last_error = "Error desconocido"
            
            # Estrategia 1: Verificar por extensi√≥n primero (m√°s r√°pido)
            url_lower = url.lower()
            if any(ext in url_lower for ext in ['.m3u8', '.mpd']):
                ext_type = "HLS" if '.m3u8' in url_lower else "DASH"
                
                for attempt, ua in enumerate(user_agents[:4], 1):  # Probar 4 user agents
                    success, result = try_request_with_retry(url, ua, parsed_url, timeout, attempt)
                    if success:
                        if result == "valid_extension":
                            return True, f"‚úÖ {ext_type} v√°lido por extensi√≥n (m√©todo {attempt})"
                        else:
                            return True, f"‚úÖ {result} (m√©todo {attempt})"
                    else:
                        last_error = result
                        if "103" in str(result) or "reset" in str(result).lower():
                            time.sleep(2)  # Pausa m√°s larga para errores de conexi√≥n
                        else:
                            time.sleep(0.8)
                
                # Si todos los intentos fallaron pero tiene extensi√≥n v√°lida
                if any(indicator in str(last_error).lower() for indicator in ['403', '103', 'reset', 'connection']):
                    return True, f"‚úÖ {ext_type} v√°lido por extensi√≥n (bypass error {last_error})"
            
            # Estrategia 2: Validaci√≥n completa para otras URLs
            for attempt, ua in enumerate(user_agents[:3], 1):
                success, result = try_request_with_retry(url, ua, parsed_url, timeout, attempt, full_validation=True)
                if success:
                    return True, f"‚úÖ {result} (m√©todo {attempt})"
                else:
                    last_error = result
                    if "103" in str(result) or "reset" in str(result).lower():
                        time.sleep(2)
                    else:
                        time.sleep(1)
            
            # Estrategia 3: Para errores espec√≠ficos, verificar si la URL parece v√°lida
            error_str = str(last_error).lower()
            if any(error_code in error_str for error_code in ['403', '103', 'reset', 'connection']):
                if any(indicator in url_lower for indicator in [
                    'm3u8', 'mpd', 'stream', 'live', 'hls', 'dash', 
                    'playlist', 'manifest', 'ts?', 'segment', 'channel'
                ]):
                    error_type = "403" if "403" in error_str else "103/Reset" if ("103" in error_str or "reset" in error_str) else "Conexi√≥n"
                    return True, f"‚ö†Ô∏è Posible stream v√°lido ({error_type} - Acceso restringido)"
            
            return False, last_error
        
        def try_request_with_retry(url, user_agent, parsed_url, timeout, attempt, full_validation=False, max_retries=2):
            """
            Intenta hacer request con reintentos para manejar errores de conexi√≥n
            """
            for retry in range(max_retries + 1):
                try:
                    headers = build_headers(user_agent, parsed_url, attempt)
                    req = urllib.request.Request(url, headers=headers)
                    
                    with urllib.request.urlopen(req, timeout=timeout) as response:
                        status_code = response.getcode()
                        
                        # Manejar c√≥digos de estado espec√≠ficos
                        if status_code == 103:
                            if retry < max_retries:
                                time.sleep(2)  # Esperar antes de reintentar
                                continue
                            else:
                                return False, "HTTP 103 (Early Hints - conexi√≥n inestable)"
                        
                        if not (200 <= status_code < 400):
                            return False, f"HTTP {status_code}"
                        
                        content_type = response.headers.get('content-type', '').lower()
                        
                        if full_validation:
                            content_sample = safe_read_content(response)
                            is_valid_stream, stream_type = check_streaming_content(content_sample, content_type, url)
                            
                            if is_valid_stream:
                                return True, stream_type
                            else:
                                return False, "No es contenido de streaming v√°lido"
                        else:
                            # Validaci√≥n r√°pida por extensi√≥n
                            return True, "valid_extension"
                            
                except urllib.error.HTTPError as e:
                    if e.code == 403:
                        return False, "HTTP 403 (Acceso denegado)"
                    elif e.code == 103:
                        if retry < max_retries:
                            time.sleep(2)
                            continue
                        else:
                            return False, "HTTP 103 (Early Hints persistente)"
                    else:
                        return False, f"HTTP {e.code}"
                        
                except urllib.error.URLError as e:
                    error_msg = str(e.reason).lower()
                    if any(reset_indicator in error_msg for reset_indicator in [
                        'connection reset', 'connection aborted', 'connection refused',
                        'reset by peer', 'broken pipe', 'connection closed'
                    ]):
                        if retry < max_retries:
                            time.sleep(3)  # Pausa m√°s larga para resets
                            continue
                        else:
                            return False, f"Conexi√≥n reiniciada ({str(e.reason)[:50]})"
                    else:
                        return False, f"URL Error: {str(e.reason)[:50]}"
                        
                except socket.timeout:
                    if retry < max_retries:
                        time.sleep(2)
                        continue
                    else:
                        return False, "Timeout (conexi√≥n lenta)"
                        
                except ConnectionResetError:
                    if retry < max_retries:
                        time.sleep(3)
                        continue
                    else:
                        return False, "Connection Reset Error"
                        
                except Exception as e:
                    error_msg = str(e).lower()
                    if any(reset_indicator in error_msg for reset_indicator in [
                        'reset', 'connection', 'broken', 'aborted'
                    ]):
                        if retry < max_retries:
                            time.sleep(2)
                            continue
                        else:
                            return False, f"Error de conexi√≥n: {str(e)[:50]}"
                    else:
                        return False, f"Error: {str(e)[:50]}"
            
            return False, "M√°ximo de reintentos alcanzado"
        
        def safe_read_content(response, max_bytes=8192):
            """
            Lee contenido de respuesta de forma segura manejando diferentes codificaciones
            """
            try:
                # Leer bytes raw
                raw_content = response.read(max_bytes)
                
                if not raw_content:
                    return ""
                
                # Intentar diferentes codificaciones en orden de preferencia
                encodings_to_try = ['utf-8', 'iso-8859-1', 'windows-1252', 'ascii']
                
                for encoding in encodings_to_try:
                    try:
                        decoded_content = raw_content.decode(encoding, errors='ignore')
                        # Verificar que el contenido decodificado tiene sentido
                        if decoded_content and len(decoded_content.strip()) > 0:
                            return decoded_content
                    except (UnicodeDecodeError, LookupError):
                        continue
                
                # Si todo falla, usar decode con errores ignore y UTF-8
                try:
                    return raw_content.decode('utf-8', errors='ignore')
                except:
                    # √öltimo recurso: convertir a string ignorando caracteres problem√°ticos
                    return str(raw_content, errors='ignore')
                    
            except Exception as e:
                print(f"‚ö†Ô∏è Error al leer contenido: {str(e)}")
                return ""
        
        def build_headers(user_agent, parsed_url, attempt):
            """
            Construye headers espec√≠ficos seg√∫n el intento y dominio
            """
            headers = {
                'User-Agent': user_agent,
                'Accept': '*/*',
                'Accept-Language': 'en-US,en;q=0.9',
                'Accept-Encoding': 'identity',
                'Connection': 'keep-alive',
                'Cache-Control': 'no-cache',
                'Pragma': 'no-cache'
            }
            
            # Headers espec√≠ficos seg√∫n el intento
            if attempt == 1:
                headers['DNT'] = '1'
                headers['Upgrade-Insecure-Requests'] = '1'
            elif attempt == 2:
                headers['Sec-Fetch-Mode'] = 'cors'
                headers['Sec-Fetch-Site'] = 'cross-site'
            elif attempt >= 3:
                # Simular request desde reproductor de video
                headers['Accept'] = 'video/webm,video/ogg,video/*;q=0.9,application/ogg;q=0.7,audio/*;q=0.6,*/*;q=0.5'
                headers['Range'] = 'bytes=0-'
            
            # Headers espec√≠ficos por dominio
            domain = parsed_url.netloc.lower()
            if any(provider in domain for provider in ['cloudfront', 'amazonaws', 'azure']):
                headers['Origin'] = f"{parsed_url.scheme}://{parsed_url.netloc}"
            elif any(provider in domain for provider in ['youtube', 'googlevideo']):
                headers['Referer'] = 'https://www.youtube.com/'
            elif any(provider in domain for provider in ['twitch', 'ttvnw']):
                headers['Referer'] = 'https://www.twitch.tv/'
            
            if parsed_url.netloc:
                headers['Referer'] = headers.get('Referer', f"{parsed_url.scheme}://{parsed_url.netloc}/")
            
            return headers
        
        def check_streaming_content(content, content_type, url):
            """
            Verifica si el contenido es realmente un stream v√°lido
            """
            if not content:
                return False, "Contenido vac√≠o"
                
            content_lower = content.lower()
            url_lower = url.lower()
            
            # 1. Verificar por extensi√≥n de archivo en URL
            if any(ext in url_lower for ext in ['.m3u8', '.mpd', '.ts', '.m4s']):
                if '.m3u8' in url_lower:
                    return True, "HLS (m3u8 en URL)"
                elif '.mpd' in url_lower:
                    return True, "DASH (mpd en URL)"
                elif '.ts' in url_lower:
                    return True, "Transport Stream"
                elif '.m4s' in url_lower:
                    return True, "DASH Segment"
            
            # 2. Verificar por Content-Type
            streaming_content_types = [
                'application/vnd.apple.mpegurl',  # HLS
                'application/x-mpegurl',         # HLS
                'application/dash+xml',          # DASH
                'video/mp2t',                    # MPEG-TS
                'application/octet-stream'       # Puede ser streaming
            ]
            
            if any(ct in content_type for ct in streaming_content_types):
                if 'mpegurl' in content_type:
                    return True, "HLS (Content-Type)"
                elif 'dash+xml' in content_type:
                    return True, "DASH (Content-Type)"
                elif 'mp2t' in content_type:
                    return True, "MPEG-TS (Content-Type)"
            
            # 3. Verificar contenido HLS (m3u8)
            hls_indicators = [
                '#extm3u',
                '#ext-x-version',
                '#ext-x-targetduration',
                '#ext-x-media-sequence',
                '#extinf:',
                '#ext-x-stream-inf',
                '#ext-x-playlist-type'
            ]
            
            if any(indicator in content_lower for indicator in hls_indicators):
                return True, "HLS Playlist"
            
            # 4. Verificar contenido DASH (mpd)
            dash_indicators = [
                '<mpd',
                'urn:mpeg:dash:schema',
                '<period',
                '<adaptationset',
                '<representation',
                'dash:profile'
            ]
            
            if any(indicator in content_lower for indicator in dash_indicators):
                return True, "DASH Manifest"
            
            # 5. Verificar si contiene enlaces a segmentos de video
            segment_patterns = [
                r'\.ts\b',           # Segmentos TS
                r'\.m4s\b',         # Segmentos DASH
                r'\.mp4\b',         # Segmentos MP4
                r'seg-\d+',         # Patrones de segmentos
                r'chunk-\d+',       # Patrones de chunks
                r'fragment-\d+'     # Patrones de fragmentos
            ]
            
            for pattern in segment_patterns:
                if re.search(pattern, content_lower):
                    return True, "Contiene segmentos de video"
            
            # 6. Verificar headers de streaming en el contenido
            streaming_headers = [
                'x-media-sequence',
                'x-targetduration',
                'x-version'
            ]
            
            if any(header in content_lower for header in streaming_headers):
                return True, "Headers de streaming"
            
            # 7. Verificar si es contenido binario que podr√≠a ser video
            if len(content) > 100:
                try:
                    # Intentar obtener los primeros bytes para verificar magic numbers
                    content_start = content[:100].encode('utf-8', errors='ignore')[:100]
                    
                    # Magic numbers para diferentes formatos
                    video_signatures = [
                        b'\x00\x00\x00\x1cftyp',     # MP4
                        b'\x00\x00\x00\x18ftypmp4',  # MP4
                        b'G@',                        # MPEG-TS
                        b'G\x40',                     # MPEG-TS
                        b'\x47',                      # MPEG-TS sync byte
                    ]
                    
                    for sig in video_signatures:
                        if sig in content_start:
                            return True, "Contenido de video binario"
                except Exception:
                    # Si hay error al procesar, continuar sin verificar magic numbers
                    pass
            
            return False, "No es contenido de streaming"
        
        def parse_stream_block(block_text):
            try:
                title_match = re.search(r'Title:\s*"([^"]*)"', block_text)
                title = title_match.group(1) if title_match else ""
                
                stream_match = re.search(r'Stream:\s*"([^"]*)"', block_text)
                stream_url = stream_match.group(1) if stream_match else ""
                
                artist_match = re.search(r'Artist:\s*"([^"]*)"', block_text)
                artist = artist_match.group(1) if artist_match else "web"
                
                stream_format_match = re.search(r'streamFormat:\s*"([^"]*)"', block_text)
                stream_format = stream_format_match.group(1) if stream_format_match else "hls|mts"
                
                switching_strategy_match = re.search(r'SwitchingStrategy:\s*"([^"]*)"', block_text)
                switching_strategy = switching_strategy_match.group(1) if switching_strategy_match else "full-adaptation"
                
                logo_match = re.search(r'Logo:\s*"([^"]*)"', block_text)
                logo = logo_match.group(1) if logo_match else "https://raw.githubusercontent.com/jsosao/Bics/main/picons/no_logo.png"
                
                live_match = re.search(r'Live:\s*(true|false)', block_text)
                live = live_match.group(1) if live_match else "true"
                
                return {
                    'artist': artist,
                    'title': title,
                    'stream_format': stream_format,
                    'switching_strategy': switching_strategy,
                    'logo': logo,
                    'stream_url': stream_url,
                    'live': live
                }
            except Exception as e:
                print(f"‚ö†Ô∏è Error al parsear bloque: {str(e)}")
                return None
        
        def update_title_status(title, is_online):
            has_x_marker = title.startswith("[X] ")
            
            if is_online:
                if has_x_marker:
                    return title[4:]  # Remover [X] si est√° online
                else:
                    return title
            else:
                if not has_x_marker:
                    return f"[X] {title}"  # Agregar [X] si est√° offline
                else:
                    return title
        
        def create_stream_block(stream_data):
            return f'''{{
            Artist: "{stream_data['artist']}"
            Title: "{stream_data['title']}"
            streamFormat: "{stream_data['stream_format']}"
            SwitchingStrategy: "{stream_data['switching_strategy']}"
            Logo: "{stream_data['logo']}"
            Stream: "{stream_data['stream_url']}"
            Live: {stream_data['live']}
        }}'''
        
        # Configuraci√≥n - directorio a procesar
        directory_path = "country/country"
        validate_urls = "${{ github.event.inputs.validate_urls }}" != "false"
        update_file = "${{ github.event.inputs.update_file }}" == "true"
        
        if "${{ github.event_name }}" == "schedule":
            validate_urls = True
            update_file = True
        
        print("üéØ === VALIDADOR AVANZADO DE STREAMS - GITHUB ACTION ===")
        print(f"üìÅ Procesando directorio: {directory_path}")
        print(f"üîç Validar URLs: {validate_urls}")
        print(f"üíæ Actualizar archivo: {update_file}")
        print("üî¨ Validaci√≥n mejorada: Verifica contenido de streaming real (m3u8, mpd, etc.)")
        print("üõ°Ô∏è Manejo mejorado de codificaci√≥n UTF-8/Unicode")
        print()
        
        # Verificar si el directorio existe
        if not os.path.exists(directory_path):
            print(f"‚ùå Directorio {directory_path} no encontrado")
            exit(1)
        
        # Obtener todos los archivos del directorio
        try:
            all_files = os.listdir(directory_path)
            # Filtrar solo archivos (no directorios) y excluir archivos ocultos
            file_paths = [os.path.join(directory_path, f) for f in all_files 
                         if os.path.isfile(os.path.join(directory_path, f)) and not f.startswith('.')]
            
            if not file_paths:
                print(f"‚ùå No se encontraron archivos en {directory_path}")
                exit(1)
                
            print(f"üìã Archivos encontrados: {len(file_paths)}")
            for fp in file_paths:
                print(f"   - {fp}")
            print()
            
        except Exception as e:
            print(f"‚ùå Error al leer el directorio {directory_path}: {str(e)}")
            exit(1)
        
        total_streams = 0
        total_valid = 0
        total_invalid = 0
        total_updated = 0
        processed_files = 0
        detailed_log = []
        
        # Procesar cada archivo
        for file_path in file_paths:
            print(f"\nüìÇ === PROCESANDO: {file_path} ===")
            
            # Leer archivo con manejo mejorado de codificaci√≥n
            try:
                # Intentar UTF-8 primero
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                except UnicodeDecodeError:
                    # Si falla UTF-8, intentar con otras codificaciones
                    encodings_to_try = ['iso-8859-1', 'windows-1252', 'ascii']
                    content = None
                    for encoding in encodings_to_try:
                        try:
                            with open(file_path, 'r', encoding=encoding) as f:
                                content = f.read()
                            print(f"üìù Archivo le√≠do con codificaci√≥n: {encoding}")
                            break
                        except UnicodeDecodeError:
                            continue
                    
                    if content is None:
                        print(f"‚ùå No se pudo leer el archivo con ninguna codificaci√≥n conocida")
                        continue
                        
            except Exception as e:
                print(f"‚ùå Error al leer el archivo {file_path}: {str(e)}")
                continue
            
            # Procesar bloques
            blocks = []
            current_block = ""
            brace_count = 0
            
            for line in content.split('\n'):
                line = line.strip()
                if not line:
                    continue
                    
                current_block += line + '\n'
                brace_count += line.count('{') - line.count('}')
                
                if brace_count == 0 and current_block.strip():
                    blocks.append(current_block.strip())
                    current_block = ""
            
            if not blocks:
                print(f"‚ùå No se encontraron bloques v√°lidos en {file_path}")
                continue
            
            print(f"üìä Encontrados {len(blocks)} streams en {file_path}")
            total_streams += len(blocks)
            
            updated_blocks = []
            valid_count = 0
            invalid_count = 0
            updated_count = 0
            
            for i, block in enumerate(blocks, 1):
                stream_data = parse_stream_block(block)
                
                if not stream_data:
                    updated_blocks.append(block)
                    continue
                
                original_title = stream_data['title']
                stream_url = stream_data['stream_url']
                
                if validate_urls and stream_url:
                    print(f"üîç Validando {i}/{len(blocks)}: {original_title[:50]}...")
                    
                    # Validaci√≥n mejorada
                    is_online, validation_detail = validate_stream_url(stream_url)
                    
                    if is_online:
                        valid_count += 1
                        print(f"  {validation_detail}")
                        detailed_log.append(f"‚úÖ {file_path} - {original_title}: {validation_detail}")
                    else:
                        invalid_count += 1
                        print(f"  ‚ùå {validation_detail}")
                        detailed_log.append(f"‚ùå {file_path} - {original_title}: {validation_detail}")
                    
                    new_title = update_title_status(original_title, is_online)
                    
                    if new_title != original_title:
                        updated_count += 1
                        print(f"  üîÑ Actualizado: '{original_title}' ‚Üí '{new_title}'")
                    
                    stream_data['title'] = new_title
                    
                    # Pausa entre validaciones para no sobrecargar servidores
                    time.sleep(1)
                
                updated_block = create_stream_block(stream_data)
                updated_blocks.append(updated_block)
            
            # Generar contenido final para este archivo
            final_content = '\n'.join(updated_blocks)
            
            # Estad√≠sticas del archivo
            print(f"\nüìà ESTAD√çSTICAS PARA {file_path}:")
            print(f"   Streams procesados: {len(blocks)}")
            if validate_urls:
                print(f"   URLs v√°lidas: {valid_count}")
                print(f"   URLs inv√°lidas: {invalid_count}")
                print(f"   T√≠tulos actualizados: {updated_count}")
                if (valid_count + invalid_count) > 0:
                    percentage = (valid_count / (valid_count + invalid_count)) * 100
                    print(f"   Porcentaje v√°lidas: {percentage:.1f}%")
            
            # Acumular totales
            total_valid += valid_count
            total_invalid += invalid_count
            total_updated += updated_count
            processed_files += 1
            
            # Guardar archivo si hay cambios (con manejo mejorado de codificaci√≥n)
            if update_file and updated_count > 0:
                try:
                    # Intentar guardar en UTF-8 primero
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(final_content)
                    print(f"üíæ Archivo actualizado: {file_path}")
                except Exception as e:
                    print(f"‚ùå Error al guardar {file_path}: {str(e)}")
        
        # Estad√≠sticas totales
        print(f"\nüéØ === ESTAD√çSTICAS TOTALES ===")
        print(f"   Directorio procesado: {directory_path}")
        print(f"   Total archivos procesados: {processed_files}")
        print(f"   Total streams: {total_streams}")
        if validate_urls:
            print(f"   Total URLs v√°lidas: {total_valid}")
            print(f"   Total URLs inv√°lidas: {total_invalid}")
            print(f"   Total t√≠tulos actualizados: {total_updated}")
            if (total_valid + total_invalid) > 0:
                total_percentage = (total_valid / (total_valid + total_invalid)) * 100
                print(f"   Porcentaje total v√°lidas: {total_percentage:.1f}%")
        
        # Guardar reporte detallado (con codificaci√≥n UTF-8)
        try:
            with open("validation_report_country.txt", 'w', encoding='utf-8') as f:
                f.write(f"REPORTE DETALLADO DE VALIDACI√ìN DE STREAMS\n")
                f.write(f"=========================================\n")
                f.write(f"Fecha: $(date)\n")
                f.write(f"Directorio procesado: {directory_path}\n")
                f.write(f"Archivos procesados: {processed_files}\n")
                f.write(f"Total streams: {total_streams}\n")
                if validate_urls:
                    f.write(f"Total URLs v√°lidas: {total_valid}\n")
                    f.write(f"Total URLs inv√°lidas: {total_invalid}\n")
                    f.write(f"Total t√≠tulos actualizados: {total_updated}\n")
                    if (total_valid + total_invalid) > 0:
                        total_percentage = (total_valid / (total_valid + total_invalid)) * 100
                        f.write(f"Porcentaje total v√°lidas: {total_percentage:.1f}%\n")
                    f.write(f"\nDETALLE DE VALIDACIONES:\n")
                    f.write(f"========================\n")
                    for log_entry in detailed_log:
                        # Limpiar caracteres problem√°ticos del log
                        clean_entry = log_entry.encode('utf-8', errors='ignore').decode('utf-8')
                        f.write(f"{clean_entry}\n")
        except Exception as e:
            print(f"‚ö†Ô∏è Error al guardar reporte: {str(e)}")
        
        print("‚úÖ Proceso completado con validaci√≥n mejorada")
        print("üìã Los streams ahora se validan verificando contenido real de streaming")
        print("üõ°Ô∏è Manejo mejorado de codificaci√≥n para evitar errores Unicode")
        EOF
