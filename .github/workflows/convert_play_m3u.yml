name: Converter Play M3U

on:
  schedule:
    - cron: '15 6 * * *'  # Se ejecuta diariamente a medianoche
  workflow_dispatch:  # Permite ejecuciÃ³n manual

jobs:
  convert:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'

    - name: Download and convert M3U file
      env:
        M3U_URL: ${{ secrets.PLAY_M3U_URL }}
      run: |
        cd $GITHUB_WORKSPACE
        python3 << 'EOF'
        import urllib.request
        import re
        import os
        import json
        import unicodedata


        # URL del archivo M3U desde variable de entorno (GitHub Secret)
        url = os.environ.get('M3U_URL')
        if not url:
            print("âŒ ERROR: No se encontrÃ³ la variable M3U_URL")
            print("Verifica que el secret PLAY_M3U_URL estÃ© configurado en GitHub")
            exit(1)
        
        print(f"âœ“ URL cargada desde secret PLAY_M3U_URL correctamente")
        
        # Descargar el archivo
        print("\nDescargando archivo M3U...")
        try:
            with urllib.request.urlopen(url) as response:
                content = response.read().decode('utf-8')
            print("âœ“ Archivo M3U descargado exitosamente")
        except Exception as e:
            print(f"âŒ Error al descargar el archivo M3U: {e}")
            exit(1)
        
        # Logo por defecto
        default_logo = "https://raw.githubusercontent.com/jsosao/Bics/main/picons/no_logo.png"
        picons_base_url = "https://raw.githubusercontent.com/jsosao/Bics/main/picons/"


        # ============================================================
        # FUNCIONES AUXILIARES
        # ============================================================
        
        def normalize_text(text):
            """Normaliza el texto removiendo acentos, espacios y caracteres especiales"""
            # Remover acentos
            text = unicodedata.normalize('NFD', text)
            text = ''.join(char for char in text if unicodedata.category(char) != 'Mn')
            
            # Eliminar prefijos comunes
            prefixes_to_remove = ["HD", "SD", "FHD", "UHD", "4K", "ARG", "MEX"]
            for prefix in prefixes_to_remove:
                # Eliminar como palabra completa
                text = re.sub(r'\b' + prefix + r'\b', '', text, flags=re.IGNORECASE)
            
            # Convertir a minÃºsculas y reemplazar espacios y caracteres especiales
            text = re.sub(r'[^\w\s]', '', text.lower())
            text = re.sub(r'\s+', '_', text.strip())
            
            return text
        
        def get_github_directory_contents(api_url):
            """Obtiene el contenido de un directorio de GitHub usando la API"""
            try:
                req = urllib.request.Request(api_url)
                req.add_header('User-Agent', 'Mozilla/5.0')
                
                with urllib.request.urlopen(req) as response:
                    if response.status == 200:
                        data = response.read().decode('utf-8')
                        return json.loads(data)
                    else:
                        print(f"âš  Error al acceder a {api_url}: {response.status}")
                        return []
            except Exception as e:
                print(f"âš  Error al obtener contenido: {e}")
                return []
        
        def scan_directory_recursive(path=""):
            """Escanea recursivamente todos los directorios para encontrar archivos PNG"""
            api_url = f"https://api.github.com/repos/jsosao/Bics/contents/picons{path}"
            contents = get_github_directory_contents(api_url)
            
            logos = []
            
            for item in contents:
                if item['type'] == 'file' and item['name'].endswith('.png'):
                    # Crear la URL completa del logo
                    logo_url = picons_base_url + path.lstrip('/') + ('/' if path else '') + item['name']
                    # Crear el nombre normalizado para bÃºsqueda
                    logo_name = item['name'].replace('.png', '')
                    logos.append({
                        'name': logo_name,
                        'normalized_name': normalize_text(logo_name),
                        'url': logo_url,
                        'path': path
                    })
                elif item['type'] == 'dir':
                    # Omitir la carpeta "country"
                    if item['name'] not in ['country']:
                        subfolder_path = path + '/' + item['name']
                        logos.extend(scan_directory_recursive(subfolder_path))
            
            return logos
        
        def get_picons_list():
            """Obtiene la lista completa de picons disponibles en el repositorio"""
            try:
                print("Escaneando repositorio de logos recursivamente...")
                logos = scan_directory_recursive()
                print(f"âœ“ Se encontraron {len(logos)} picons disponibles")
                return logos
            except Exception as e:
                print(f"âš  No se pudo obtener la lista de picons: {e}")
                return []
        
        def find_best_logo_match(title, picons_list):
            """Encuentra la mejor coincidencia de logo para un tÃ­tulo dado"""
            if not picons_list:
                return None
            
            normalized_title = normalize_text(title)
            
            # BÃºsqueda exacta
            for logo in picons_list:
                if logo['normalized_name'] == normalized_title:
                    print(f"  â†’ Coincidencia exacta: {logo['name']}")
                    return logo['url']
            
            # BÃºsqueda por coincidencia parcial con puntuaciÃ³n
            best_match = None
            max_score = 0
            
            for logo in picons_list:
                # Calcular similitud por palabras
                logo_words = set(logo['normalized_name'].split('_'))
                title_words = set(normalized_title.split('_'))
                
                # IntersecciÃ³n de palabras
                common_words = logo_words.intersection(title_words)
                if len(common_words) > 0:
                    # PuntuaciÃ³n basada en palabras comunes y longitud
                    score = len(common_words) / max(len(logo_words), len(title_words))
                    if score > max_score and score > 0.3:  # Umbral mÃ­nimo de similitud
                        max_score = score
                        best_match = logo
            
            # Si encontramos una buena coincidencia por palabras, retornarla
            if best_match and max_score > 0.5:
                print(f"  â†’ Coincidencia por palabras ({int(max_score*100)}%): {best_match['name']}")
                return best_match['url']
            
            # BÃºsqueda por contenido (substring)
            if not best_match:
                for logo in picons_list:
                    if len(logo['normalized_name']) >= 3:
                        if normalized_title in logo['normalized_name'] or logo['normalized_name'] in normalized_title:
                            # Verificar que la longitud sea razonable
                            if len(logo['normalized_name']) >= len(normalized_title) * 0.6:
                                print(f"  â†’ Coincidencia por substring: {logo['name']}")
                                return logo['url']
            
            # Si encontramos alguna coincidencia dÃ©bil, retornarla
            if best_match:
                print(f"  â†’ Coincidencia parcial ({int(max_score*100)}%): {best_match['name']}")
                return best_match['url']
            
            return None

        def clean_title(title):
            """Limpia el tÃ­tulo de prefijos no deseados."""
            ## Eliminar prefijos especÃ­ficos
            #prefixes_to_remove = ["CINE - ", "DEPORTES - ", "CINE -", "DEPORTES -","DOC-", "NOV-", "MUS-", "INF-"]
            #for prefix in prefixes_to_remove:
            #    if prefix in title:
            #        title = title.replace(prefix, "").strip()
            
            # Eliminar todo lo que estÃ© dentro de parÃ©ntesis
            title = re.sub(r'\([^)]*\)', '', title)
            
            # Limpiar espacios mÃºltiples
            title = re.sub(r'\s+', ' ', title).strip()
            
            return title
        
        def get_country(title):
            """Determina el paÃ­s basado en el tÃ­tulo."""
            title_upper = title.upper()
            if title.startswith("AU") or "AUSTRALIA" in title_upper:
                return "au"
            elif title.startswith("UK") or "BBC" in title_upper or "BRITAIN" in title_upper:
                return "uk"
            elif title.startswith("US") or "USA" in title_upper:
                return "us"
            elif title.startswith("CA") or "CANADA" in title_upper:
                return "ca"
            elif title.startswith("ES") or "SPAIN" in title_upper or "ESPAÃ‘A" in title_upper:
                return "es"
            elif title.startswith("MX") or "MEXICO" in title_upper or "MÃ‰XICO" in title_upper:
                return "mx"
            elif title.startswith("AR") or "ARGENTINA" in title_upper:
                return "ar"
            elif title.startswith("BR") or "BRASIL" in title_upper or "BRAZIL" in title_upper:
                return "br"
            elif title.startswith("FR") or "FRANCE" in title_upper or "FRANCIA" in title_upper:
                return "fr"
            else:
                return "us"  # Default
        
        def get_tag(group_title):
            """Determina el tag basado en el group-title."""
            group_lower = group_title.lower()
            if "sport" in group_lower or "deporte" in group_lower:
                return "Sports"
            elif "radio" in group_lower:
                return "Radio"
            elif "news" in group_lower or "noticias" in group_lower:
                return "News"
            elif "movie" in group_lower or "film" in group_lower or "peliculas" in group_lower or "cine" in group_lower:
                return "Movies"
            elif "series" in group_lower or "tv show" in group_lower:
                return "Series"
            elif "music" in group_lower or "musica" in group_lower:
                return "Music"
            elif "doc" in group_lower:
                return "Documentary"
            elif "kids" in group_lower or "infantil" in group_lower:
                return "Kids"
            else:
                return "General"
        
        def should_skip_group(group_title):
            """Verifica si el grupo debe ser omitido."""
            group_lower = group_title.lower()

           ## Palabras clave que indican grupos a omitir
           # skip_keywords = ["canales-adultos", "adultos", "adult", "vod", "infantiles", "series", "estrenos", "novelas", "24/7"]
           # if any(keyword in group_lower for keyword in skip_keywords):
           #     return any(keyword in group_lower for keyword in skip_keywords)

           # include_keywords = ["canales", "canales de peliculas"]
           # return not any(keyword in group_lower for keyword in include_keywords)

          # any(keyword in group_lower for keyword in include_keywords) â†’ Â¿Contiene alguna palabra a incluir?
          # not any(ex in group_lower for ex in exclude_keywords) â†’ Â¿NO contiene ninguna palabra a excluir?
          # Si AMBAS condiciones son True, retorna True (se incluye el grupo)

            include_keywords = ["canales", "canales de peliculas"]
            skip_keywords = ["24/7", "247", "infantiles"]
            return not (any(keyword in group_lower for keyword in include_keywords) and not any(ex in group_lower for ex in skip_keywords))            
        
        def escape_url(url):
            """Escapa la URL para el formato de salida."""
            url = url.replace("http://", "http[:[/][/]]")
            url = url.replace("https://", "https[:[/][/]]")
            url = url.replace(".", "[.]")
            url = url.replace("/", "[/]")
            return url

        # ============================================================
        # PROCESAMIENTO PRINCIPAL
        # ============================================================

        print("\n" + "="*60)
        print("OBTENIENDO LISTA DE PICONS DISPONIBLES")
        print("="*60)
        picons_list = get_picons_list()

        print("\n" + "="*60)
        print("PROCESANDO CANALES - PLAY")
        print("="*60)
        
	lines = content.strip().split('\n')
        entries = []
        skipped_count = 0
        logos_original = 0
        logos_found = 0
        logos_default = 0
        
        i = 0
        while i < len(lines):
            line = lines[i].strip()
            
            if line.startswith('#EXTINF:'):
                # Extraer informaciÃ³n de la lÃ­nea EXTINF
                tvg_name_match = re.search(r'tvg-name="([^"]*)"', line)
                tvg_logo_match = re.search(r'tvg-logo="([^"]*)"', line)
                group_title_match = re.search(r'group-title="([^"]*)"', line)
                
                # El tÃ­tulo estÃ¡ al final de la lÃ­nea despuÃ©s de la Ãºltima coma
                title_match = re.search(r',(.*)$', line)
                
                tvg_name = tvg_name_match.group(1) if tvg_name_match else ""
                tvg_logo = tvg_logo_match.group(1) if tvg_logo_match else ""
                group_title = group_title_match.group(1) if group_title_match else ""
                title = title_match.group(1).strip() if title_match else tvg_name

                # Limpiar el tÃ­tulo de prefijos no deseados
                title = clean_title(title)
                
                # La siguiente lÃ­nea debe ser la URL del stream
                i += 1
                if i < len(lines):
                    stream_url = lines[i].strip()
                    
                    # Omitir grupos especificados
                    if should_skip_group(group_title):
                        print(f"âŠ— Omitiendo: '{title}' | Grupo: '{group_title}'")
                        skipped_count += 1
                        i += 1
                        continue
                  
	# Determinar el logo a usar
                    if tvg_logo and tvg_logo.strip():
                        final_logo = tvg_logo
                        logos_original += 1
                        print(f"âœ“ '{title}' | Logo: Original")
                    else:
                        # Buscar picon correspondiente
                        print(f"ðŸ” Buscando logo para: '{title}'")
                        matched_picon = find_best_logo_match(title, picons_list)
                        if matched_picon:
                            final_logo = matched_picon
                            logos_found += 1
                        else:
                            final_logo = default_logo
                            logos_default += 1
                            print(f"  â†’ Sin coincidencia, usando no_logo.png")
                    
                    # Crear la entrada
                    entry = {
                        'Artist': 'Play',
                        'Title': title,
                        'streamFormat': 'hls|mts',
                        'SwitchingStrategy': 'full-adaptation',
                        'Logo': final_logo,
                        'Stream': escape_url(stream_url),
                        'Live': True,
                        'Country': get_country(title),
                        'Tag': get_tag(group_title)
                    }
                    entries.append(entry)
            
            i += 1
        
        # Generar el archivo de salida
        output_lines = []
        for entry in entries:
            output_lines.append('{')
            output_lines.append(f'    Artist: "{entry["Artist"]}"')
            output_lines.append(f'    Title: "{entry["Title"]}"')
            output_lines.append(f'    streamFormat: "{entry["streamFormat"]}"')
            output_lines.append(f'    SwitchingStrategy: "{entry["SwitchingStrategy"]}"')
            output_lines.append(f'    Logo: "{entry["Logo"]}"')
            output_lines.append(f'    Stream: "{entry["Stream"]}"')
            output_lines.append(f'    Live: {str(entry["Live"]).lower()}')
            output_lines.append(f'    Country: "{entry["Country"]}"')
            output_lines.append(f'    Tag: "{entry["Tag"]}"')
            output_lines.append('}')
        
        output_content = '\n'.join(output_lines)
        
        # Guardar el archivo sin extensiÃ³n
        output_path = "country/country/latin"
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(output_content)
        
        # EstadÃ­sticas finales
        print("\n" + "="*60)
        print("RESUMEN FINAL - PLAY")
        print("="*60)
        print(f"âœ“ Archivo guardado en: {output_path}")
        print(f"âœ“ Total de canales procesados: {len(entries)}")
        print(f"âŠ— Total de canales omitidos: {skipped_count}")
        print(f"\nDistribuciÃ³n de logos:")
        print(f"  âœ“ Logos originales del M3U: {logos_original} ({logos_original*100//len(entries) if entries else 0}%)")
        print(f"  ðŸ” Picons encontrados automÃ¡ticamente: {logos_found} ({logos_found*100//len(entries) if entries else 0}%)")
        print(f"  âš  Logos default (no_logo.png): {logos_default} ({logos_default*100//len(entries) if entries else 0}%)")
        print(f"\nTotal con logo especÃ­fico: {logos_original + logos_found} ({(logos_original + logos_found)*100//len(entries) if entries else 0}%)")
        print("="*60)
        EOF
        
    - name: Commit and push changes
      run: |
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        git add country/country/latin
        git diff --staged --quiet || git commit -m "ðŸ¤–ðŸ¤– [Bot] Update latin - $(date +'%Y-%m-%d %H:%M:%S')"
        git push  
